{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial 3\n",
    "\n",
    "Architecture:\n",
    "\n",
    "- 2 convolutional layers with max pooling after every layer\n",
    "- 2 256-unit fully-connected layers\n",
    "- Batch normalization after every layer\n",
    "\n",
    "Changes from Trial 2:\n",
    "\n",
    "- Fewer units in fully-connected output layers\n",
    "- Added batch normalization\n",
    "\n",
    "Results:\n",
    "\n",
    "- Best validation loss: 0.482 (Epoch 8/30)\n",
    "- ~16 mins per epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "\n",
    "# The training set just has blanks instead of 0s\n",
    "train_labels = pd.read_csv(\"../CheXpert-v1.0-small/train.csv\").fillna(0)\n",
    "train_labels[\"Path\"] = '../' + train_labels[\"Path\"]\n",
    "validation_labels = pd.read_csv('../CheXpert-v1.0-small/valid.csv')\n",
    "validation_labels[\"Path\"] = '../' + validation_labels[\"Path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out Lateral images.  We'll train two models -> one for lateral and one for frontal\n",
    "\n",
    "frontal_train_labels = train_labels[train_labels['Frontal/Lateral'] == 'Frontal']\n",
    "frontal_validation_labels = validation_labels[validation_labels['Frontal/Lateral'] == 'Frontal']\n",
    "\n",
    "# Filter out uncertains in the training dataset.  There are no uncertains in the validation dataset.\n",
    "frontal_train_labels = frontal_train_labels[frontal_train_labels[\"Lung Opacity\"] != -1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = datagen.flow_from_dataframe(dataframe=frontal_train_labels,\n",
    "                                            directory=\".\",\n",
    "                                            x_col=\"Path\",\n",
    "                                            y_col=['Lung Opacity'],\n",
    "                                            class_mode = \"raw\",\n",
    "                                            color_mode='grayscale',\n",
    "                                            target_size=(100, 100),\n",
    "                                            batch_size=32)\n",
    "validation_datagen = datagen.flow_from_dataframe(dataframe=frontal_validation_labels,\n",
    "                                            directory=\".\",\n",
    "                                            x_col=\"Path\",\n",
    "                                            y_col=['Lung Opacity'],\n",
    "                                            class_mode = \"raw\",\n",
    "                                            color_mode='grayscale',\n",
    "                                            target_size=(100, 100),\n",
    "                                            batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (5, 5), input_shape=(100, 100, 1), activation='relu', use_bias=False))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(activation=\"relu\", units=256))\n",
    "classifier.add(Dense(activation=\"relu\", units=256))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "classifier.fit_generator(\n",
    "    train_datagen,\n",
    "    steps_per_epoch=5280,\n",
    "    epochs=120,\n",
    "    validation_data=validation_datagen,\n",
    "    validation_steps=800,\n",
    "    workers=4,\n",
    "    verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
