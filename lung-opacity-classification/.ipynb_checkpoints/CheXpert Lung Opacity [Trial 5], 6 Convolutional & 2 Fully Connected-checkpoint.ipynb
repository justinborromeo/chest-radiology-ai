{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'CheXpert-v1.0-small/train.csv' does not exist: b'CheXpert-v1.0-small/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ea62d6e81d53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# The training set just has blanks instead of 0s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CheXpert-v1.0-small/train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mvalidation_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CheXpert-v1.0-small/valid.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'CheXpert-v1.0-small/train.csv' does not exist: b'CheXpert-v1.0-small/train.csv'"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "\n",
    "# The training set just has blanks instead of 0s\n",
    "train_labels = pd.read_csv(\"CheXpert-v1.0-small/train.csv\").fillna(0)\n",
    "validation_labels = pd.read_csv('CheXpert-v1.0-small/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out Lateral images.  We'll train two models -> one for lateral and one for frontal\n",
    "\n",
    "frontal_train_labels = train_labels[train_labels['Frontal/Lateral'] == 'Frontal']\n",
    "frontal_validation_labels = validation_labels[validation_labels['Frontal/Lateral'] == 'Frontal']\n",
    "\n",
    "# Filter out uncertains in the training dataset.  There are no uncertains in the validation dataset.\n",
    "frontal_train_labels = frontal_train_labels[frontal_train_labels[\"Lung Opacity\"] != -1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontal_train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontal_validation_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "      <td>186596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.629365</td>\n",
       "      <td>0.090967</td>\n",
       "      <td>-0.005177</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>0.504893</td>\n",
       "      <td>0.031474</td>\n",
       "      <td>0.200149</td>\n",
       "      <td>-0.060596</td>\n",
       "      <td>-0.059390</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.080173</td>\n",
       "      <td>0.357596</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.036276</td>\n",
       "      <td>0.558115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.821530</td>\n",
       "      <td>0.287562</td>\n",
       "      <td>0.317897</td>\n",
       "      <td>0.386847</td>\n",
       "      <td>0.499977</td>\n",
       "      <td>0.203722</td>\n",
       "      <td>0.532046</td>\n",
       "      <td>0.433404</td>\n",
       "      <td>0.322723</td>\n",
       "      <td>0.553443</td>\n",
       "      <td>0.317387</td>\n",
       "      <td>0.569870</td>\n",
       "      <td>0.148507</td>\n",
       "      <td>0.200450</td>\n",
       "      <td>0.506179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age     No Finding  Enlarged Cardiomediastinum  \\\n",
       "count  186596.000000  186596.000000               186596.000000   \n",
       "mean       60.629365       0.090967                   -0.005177   \n",
       "std        17.821530       0.287562                    0.317897   \n",
       "min         0.000000       0.000000                   -1.000000   \n",
       "25%        49.000000       0.000000                    0.000000   \n",
       "50%        62.000000       0.000000                    0.000000   \n",
       "75%        74.000000       0.000000                    0.000000   \n",
       "max        90.000000       1.000000                    1.000000   \n",
       "\n",
       "        Cardiomegaly   Lung Opacity    Lung Lesion          Edema  \\\n",
       "count  186596.000000  186596.000000  186596.000000  186596.000000   \n",
       "mean        0.087510       0.504893       0.031474       0.200149   \n",
       "std         0.386847       0.499977       0.203722       0.532046   \n",
       "min        -1.000000       0.000000      -1.000000      -1.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       1.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       0.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       Consolidation      Pneumonia    Atelectasis   Pneumothorax  \\\n",
       "count  186596.000000  186596.000000  186596.000000  186596.000000   \n",
       "mean       -0.060596      -0.059390       0.006972       0.080173   \n",
       "std         0.433404       0.322723       0.553443       0.317387   \n",
       "min        -1.000000      -1.000000      -1.000000      -1.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       Pleural Effusion  Pleural Other       Fracture  Support Devices  \n",
       "count     186596.000000  186596.000000  186596.000000    186596.000000  \n",
       "mean           0.357596       0.003848       0.036276         0.558115  \n",
       "std            0.569870       0.148507       0.200450         0.506179  \n",
       "min           -1.000000      -1.000000      -1.000000        -1.000000  \n",
       "25%            0.000000       0.000000       0.000000         0.000000  \n",
       "50%            0.000000       0.000000       0.000000         1.000000  \n",
       "75%            1.000000       0.000000       0.000000         1.000000  \n",
       "max            1.000000       1.000000       1.000000         1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontal_train_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.00000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.00000</td>\n",
       "      <td>202.0</td>\n",
       "      <td>202.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.816832</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.519802</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>0.579208</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.371287</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.336303</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>0.500849</td>\n",
       "      <td>0.470184</td>\n",
       "      <td>0.494913</td>\n",
       "      <td>0.07036</td>\n",
       "      <td>0.406828</td>\n",
       "      <td>0.366038</td>\n",
       "      <td>0.195511</td>\n",
       "      <td>0.484349</td>\n",
       "      <td>0.183355</td>\n",
       "      <td>0.466397</td>\n",
       "      <td>0.07036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
       "count  202.000000  202.000000                  202.000000    202.000000   \n",
       "mean    60.816832    0.128713                    0.519802      0.326733   \n",
       "std     18.336303    0.335714                    0.500849      0.470184   \n",
       "min     18.000000    0.000000                    0.000000      0.000000   \n",
       "25%     48.250000    0.000000                    0.000000      0.000000   \n",
       "50%     62.500000    0.000000                    1.000000      0.000000   \n",
       "75%     74.750000    0.000000                    1.000000      1.000000   \n",
       "max     90.000000    1.000000                    1.000000      1.000000   \n",
       "\n",
       "       Lung Opacity  Lung Lesion       Edema  Consolidation   Pneumonia  \\\n",
       "count    202.000000    202.00000  202.000000     202.000000  202.000000   \n",
       "mean       0.579208      0.00495    0.207921       0.158416    0.039604   \n",
       "std        0.494913      0.07036    0.406828       0.366038    0.195511   \n",
       "min        0.000000      0.00000    0.000000       0.000000    0.000000   \n",
       "25%        0.000000      0.00000    0.000000       0.000000    0.000000   \n",
       "50%        1.000000      0.00000    0.000000       0.000000    0.000000   \n",
       "75%        1.000000      0.00000    0.000000       0.000000    0.000000   \n",
       "max        1.000000      1.00000    1.000000       1.000000    1.000000   \n",
       "\n",
       "       Atelectasis  Pneumothorax  Pleural Effusion  Pleural Other  Fracture  \\\n",
       "count   202.000000    202.000000        202.000000      202.00000     202.0   \n",
       "mean      0.371287      0.034653          0.316832        0.00495       0.0   \n",
       "std       0.484349      0.183355          0.466397        0.07036       0.0   \n",
       "min       0.000000      0.000000          0.000000        0.00000       0.0   \n",
       "25%       0.000000      0.000000          0.000000        0.00000       0.0   \n",
       "50%       0.000000      0.000000          0.000000        0.00000       0.0   \n",
       "75%       1.000000      0.000000          1.000000        0.00000       0.0   \n",
       "max       1.000000      1.000000          1.000000        1.00000       0.0   \n",
       "\n",
       "       Support Devices  \n",
       "count       202.000000  \n",
       "mean          0.490099  \n",
       "std           0.501144  \n",
       "min           0.000000  \n",
       "25%           0.000000  \n",
       "50%           0.000000  \n",
       "75%           1.000000  \n",
       "max           1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontal_validation_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 186596 validated image filenames.\n",
      "Found 202 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = datagen.flow_from_dataframe(dataframe=frontal_train_labels,\n",
    "                                            directory=\".\",\n",
    "                                            x_col=\"Path\",\n",
    "                                            y_col=['Lung Opacity'],\n",
    "                                            class_mode = \"raw\",\n",
    "                                            color_mode='grayscale',\n",
    "                                            target_size=(100, 100),\n",
    "                                            batch_size=32)\n",
    "validation_datagen = datagen.flow_from_dataframe(dataframe=frontal_validation_labels,\n",
    "                                            directory=\".\",\n",
    "                                            x_col=\"Path\",\n",
    "                                            y_col=['Lung Opacity'],\n",
    "                                            class_mode = \"raw\",\n",
    "                                            color_mode='grayscale',\n",
    "                                            target_size=(100, 100),\n",
    "                                            batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics functions\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      " - 1864s - loss: 0.7115 - precision_m: 0.5686 - recall_m: 0.7451 - f1_m: 0.6313 - val_loss: 0.7452 - val_precision_m: 0.7723 - val_recall_m: 0.1620 - val_f1_m: 0.2597\n",
      "Epoch 2/120\n",
      " - 1870s - loss: 0.6623 - precision_m: 0.5871 - recall_m: 0.7368 - f1_m: 0.6452 - val_loss: 0.6471 - val_precision_m: 0.6701 - val_recall_m: 0.8780 - val_f1_m: 0.7550\n",
      "Epoch 3/120\n",
      " - 1858s - loss: 0.6592 - precision_m: 0.5968 - recall_m: 0.7149 - f1_m: 0.6422 - val_loss: 0.6462 - val_precision_m: 0.7793 - val_recall_m: 0.3209 - val_f1_m: 0.4440\n",
      "Epoch 4/120\n",
      " - 1859s - loss: 0.6559 - precision_m: 0.5993 - recall_m: 0.7190 - f1_m: 0.6455 - val_loss: 0.6486 - val_precision_m: 0.5788 - val_recall_m: 1.0000 - val_f1_m: 0.7284\n",
      "Epoch 5/120\n",
      " - 1859s - loss: 0.6547 - precision_m: 0.5987 - recall_m: 0.7328 - f1_m: 0.6515 - val_loss: 0.6263 - val_precision_m: 0.8457 - val_recall_m: 0.5185 - val_f1_m: 0.6336\n",
      "Epoch 6/120\n",
      " - 1865s - loss: 0.6550 - precision_m: 0.6017 - recall_m: 0.7223 - f1_m: 0.6483 - val_loss: 0.6102 - val_precision_m: 0.5975 - val_recall_m: 0.9837 - val_f1_m: 0.7387\n",
      "Epoch 7/120\n",
      " - 1859s - loss: 0.6527 - precision_m: 0.6037 - recall_m: 0.7152 - f1_m: 0.6469 - val_loss: 0.6130 - val_precision_m: 0.8185 - val_recall_m: 0.5757 - val_f1_m: 0.6668\n",
      "Epoch 8/120\n",
      " - 1860s - loss: 0.6488 - precision_m: 0.6065 - recall_m: 0.7340 - f1_m: 0.6571 - val_loss: 0.5920 - val_precision_m: 0.7411 - val_recall_m: 0.8853 - val_f1_m: 0.8017\n",
      "Epoch 9/120\n",
      " - 1862s - loss: 0.6478 - precision_m: 0.6094 - recall_m: 0.7330 - f1_m: 0.6585 - val_loss: 0.5867 - val_precision_m: 0.8692 - val_recall_m: 0.5370 - val_f1_m: 0.6551\n",
      "Epoch 10/120\n",
      " - 1866s - loss: 0.6467 - precision_m: 0.6090 - recall_m: 0.7385 - f1_m: 0.6604 - val_loss: 0.5716 - val_precision_m: 0.7802 - val_recall_m: 0.7879 - val_f1_m: 0.7780\n",
      "Epoch 11/120\n",
      " - 1916s - loss: 0.6472 - precision_m: 0.6074 - recall_m: 0.7441 - f1_m: 0.6618 - val_loss: 0.6229 - val_precision_m: 0.7765 - val_recall_m: 0.4701 - val_f1_m: 0.5757\n",
      "Epoch 12/120\n",
      " - 1890s - loss: 0.6457 - precision_m: 0.6088 - recall_m: 0.7401 - f1_m: 0.6607 - val_loss: 0.5155 - val_precision_m: 0.8063 - val_recall_m: 0.6480 - val_f1_m: 0.7111\n",
      "Epoch 13/120\n",
      " - 1858s - loss: 0.6463 - precision_m: 0.6084 - recall_m: 0.7525 - f1_m: 0.6659 - val_loss: 0.5311 - val_precision_m: 0.6713 - val_recall_m: 0.9751 - val_f1_m: 0.7910\n",
      "Epoch 14/120\n",
      " - 1855s - loss: 0.6430 - precision_m: 0.6114 - recall_m: 0.7484 - f1_m: 0.6661 - val_loss: 0.6689 - val_precision_m: 0.7521 - val_recall_m: 0.9070 - val_f1_m: 0.8178\n",
      "Epoch 15/120\n",
      " - 1820s - loss: 0.6419 - precision_m: 0.6148 - recall_m: 0.7391 - f1_m: 0.6641 - val_loss: 0.6311 - val_precision_m: 0.7743 - val_recall_m: 0.7855 - val_f1_m: 0.7739\n",
      "Epoch 16/120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-3c3d822471ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     callbacks=[mc])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\jborromeo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# L2 regularization uses the sum of the squares of the weights\n",
    "l2_regularization_constant = 0\n",
    "\n",
    "# 200x200 input\n",
    "# Input is kinda large, so we select larger filters for the first layer to decrease \n",
    "# size of feature maps (and hopefully speed up training).\n",
    "\n",
    "# Input: 100 x 100 x 1\n",
    "classifier.add(Conv2D(32, (5, 5), input_shape=(100, 100, 1), use_bias=False))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 96 x 96 x 32\n",
    "classifier.add(Conv2D(64, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 94 x 94 x 64\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Input: 47 x 47 x 64\n",
    "classifier.add(Conv2D(64, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 45 x 45 x 128\n",
    "classifier.add(Conv2D(64, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 43 x 43 x 128\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Input: 21 x 21 x 128\n",
    "classifier.add(Conv2D(128, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 19 x 19 x 128\n",
    "classifier.add(Conv2D(128, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 17 x 17 x 128\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Input: 8 x 8 x 128\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Input: 8192 x 1024\n",
    "classifier.add(Dense(activation=\"relu\", units=1024))\n",
    "classifier.add(Dense(activation=\"relu\", units=1024))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
    "\n",
    "classifier.compile(optimizer=Adam(learning_rate=0.002), loss='binary_crossentropy', metrics=[precision_m, recall_m, f1_m])\n",
    "\n",
    "mc = ModelCheckpoint('trial_5/weights{epoch:04d}.h5', \n",
    "                                     save_weights_only=True, period=5)\n",
    "\n",
    "os.makedirs('trial_5')\n",
    "\n",
    "# too many epochs mean overfitting, not enough epochs mean underfitting\n",
    "classifier.fit_generator(\n",
    "    train_datagen,\n",
    "    steps_per_epoch=5280,\n",
    "    epochs=120,\n",
    "    validation_data=validation_datagen,\n",
    "    validation_steps=800,\n",
    "    workers=4,\n",
    "    verbose=2,\n",
    "    callbacks=[mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial 1\n",
    "\n",
    "- 2 Convolutional Layers and 1 Fully-Connected Layer\n",
    "- No Regularization\n",
    "- Best Validation Loss: 0.53 (Epoch 7/35)\n",
    "- ~20 mins per epoch\n",
    "\n",
    "```\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (5, 5), input_shape=(200, 200, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(activation=\"relu\", units=128))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial 2\n",
    "\n",
    "- 6 convolutional layers with a max pooling layer every 2 convolutions\n",
    "- Little improvement in validation/training loss and accuracy over the first hour and a half of training\n",
    "- Best validation loss: 0.69 (last epoch for stopping)\n",
    "- ~20 mins/epoch\n",
    "\n",
    "```\n",
    "classifier = Sequential()\n",
    "\n",
    "# 200x200 input\n",
    "# Input is kinda large, so we select larger filters for the first layer to decrease \n",
    "# size of feature maps (and hopefully speed up training).\n",
    "\n",
    "# Input: 100 x 100 x 1\n",
    "classifier.add(Conv2D(32, (5, 5), input_shape=(100, 100, 1), activation='relu'))\n",
    "# Input: 96 x 96 x 32\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Input: 94 x 94 x 64\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Input: 47 x 47 x 64\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# Input: 45 x 45 x 128\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# Input: 43 x 43 x 128\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Input: 21 x 21 x 128\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# Input: 19 x 19 x 128\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# Input: 17 x 17 x 128\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Input: 8 x 8 x 128\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Input: 8192 x 512\n",
    "classifier.add(Dense(activation=\"relu\", units=512))\n",
    "classifier.add(Dense(activation=\"relu\", units=512))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial 3\n",
    "\n",
    "- 2 convolutional layers with max pooling after every layer\n",
    "- 2 512-unit fully-connected layers\n",
    "- Best validation loss: 0.45 (Epoch 21/30)\n",
    "- ~16 mins per epoch\n",
    "\n",
    "```\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (5, 5), input_shape=(100, 100, 1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(activation=\"relu\", units=512))\n",
    "classifier.add(Dense(activation=\"relu\", units=512))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial 4\n",
    "\n",
    "- Same as Trial 3 but with a batch normalization layer and 256-unit fully-connected layers\n",
    "- Best validation loss: 0.482 (Epoch 8/30)\n",
    "- ~16 mins per epoch\n",
    "\n",
    "```\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (5, 5), input_shape=(100, 100, 1), activation='relu', use_bias=False))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(activation=\"relu\", units=256))\n",
    "classifier.add(Dense(activation=\"relu\", units=256))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial 5\n",
    "\n",
    "- 6 convolutional layers and 2 fully-connected layers\n",
    "- Batch normalization after every convolutional layer\n",
    "- ReLU activation should be after pooling layer for performance (this was a mistake)\n",
    "- Dropout of 0.2 after every convolutional layer (this invalidates a random 20% of input units every training iteration).  This should help with overfitting\n",
    "- ~33 minutes per epoch\n",
    "- Best validation loss: 0.4183 (Epoch 35/65) \n",
    "\n",
    "```\n",
    "classifier = Sequential()\n",
    "\n",
    "# L2 regularization uses the sum of the squares of the weights\n",
    "l2_regularization_constant = 0\n",
    "\n",
    "# 200x200 input\n",
    "# Input is kinda large, so we select larger filters for the first layer to decrease \n",
    "# size of feature maps (and hopefully speed up training).\n",
    "\n",
    "# Input: 100 x 100 x 1\n",
    "classifier.add(Conv2D(32, (5, 5), input_shape=(100, 100, 1), use_bias=False))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 96 x 96 x 32\n",
    "classifier.add(Conv2D(64, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 94 x 94 x 64\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Input: 47 x 47 x 64\n",
    "classifier.add(Conv2D(64, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 45 x 45 x 128\n",
    "classifier.add(Conv2D(64, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 43 x 43 x 128\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Input: 21 x 21 x 128\n",
    "classifier.add(Conv2D(128, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 19 x 19 x 128\n",
    "classifier.add(Conv2D(128, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "# Input: 17 x 17 x 128\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Input: 8 x 8 x 128\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Input: 8192 x 1024\n",
    "classifier.add(Dense(activation=\"relu\", units=1024))\n",
    "classifier.add(Dense(activation=\"relu\", units=1024))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
